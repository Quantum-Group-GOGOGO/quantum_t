# quantum_t

A quantitative-trading framework built with **Python** and **PyTorch**, designed for high-frequency futures data.  
It supports full-cycle development â€” data collection, preprocessing, model training (LSTM / MLP / Transformer), and back-testing â€” in a modular and reproducible way.

---

## ğŸš€ Features

- **Data Collection**  
  Fetch and aggregate high-frequency futures data (e.g., 1-min bars) for training and back-testing.

- **Preprocessing Pipeline**  
  Clean, resample, and normalize market data with configurable window sizes and rolling statistics.

- **Model Architectures**  
  Implemented in PyTorch, including:
  - LSTM encoders for sequence learning  
  - MLP and Transformer layers for representation and prediction  
  - Custom loss functions for noisy, non-stationary data

- **Backtesting Engine**  
  Evaluate predictive models in a simulated futures environment with adjustable latency, spread, and execution parameters.

- **Modular Design**  
  Each component (data, model, training, evaluation) can run independently or be orchestrated through a unified pipeline.

---

## ğŸ“ Project Structure

```
quantum_t/
â”œâ”€ DataCollection/         # Data fetch & aggregation scripts
â”œâ”€ DataPreprocess/         # Cleaning, feature engineering & normalization
â”œâ”€ models/                 # PyTorch model definitions
â”œâ”€ training/               # Training loop & experiment configs
â”œâ”€ backtest/               # Backtesting & evaluation
â”œâ”€ utils/                  # Common utilities & logging
â”œâ”€ environment/            # Environment setup (requirements, Docker)
â”œâ”€ Docs/                   # Documentation, experiment notes
â””â”€ README.md               # Project overview
```

---

## âš™ï¸ Installation

```bash
git clone https://github.com/Quantum-Group-GOGOGO/quantum_t.git
cd quantum_t

python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

pip install -r requirements.txt
```

---

## ğŸ§  Usage Example

### 1ï¸âƒ£ Data Collection
```bash
python DataCollection/fetch_data.py --symbol NQ --bar_size '1 min' --days 30
```

### 2ï¸âƒ£ Training
```bash
python training/train_model.py
```

### 3ï¸âƒ£ Backtesting
```bash
python backtest/run_backtest.py --model checkpoints/model_latest.pt
```

---

## ğŸ“Š Example (Python API)

```python
from models import TransformerEncoder
from training import Trainer
from backtest import Backtester

# Load data
loader = DataLoader(...)
train_data, test_data = loader.load()

# Train model
model = TransformerEncoder(...)
trainer = Trainer(model, train_data)
trainer.train(epochs=50)

# Backtest
backtester = Backtester(model, test_data)
results = backtester.run()
print(results.metrics)
```

---

## ğŸ§© Dependencies

- Python â‰¥ 3.9  
- PyTorch â‰¥ 2.0  
- pandas, numpy, matplotlib  
- tqdm, pyyaml, scikit-learn

(See `requirements.txt` for full list)

---

## ğŸ¤ Contributing

Pull requests are welcome!  
Please ensure that your code:
- follows PEP8
- includes clear docstrings
- passes existing tests

---

## ğŸ“œ License

This project is released under the **MIT License**.  
See the [`LICENSE`](LICENSE) file for details.

---

## ğŸ“œ Author

Wentian Wang littlenova223@gmail.com

---

âœ³ï¸ Maintainer: [Quantum Group](https://github.com/Quantum-Group-GOGOGO)
